{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aba772c-8d71-4dac-938a-fb9cdcfcd3ba",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with Neural Networks\n",
    "\n",
    "In this assignment you will build a full training and testing pipeline for a neural sequential tagger for named entities, using RNN / LSTM.\n",
    "\n",
    "The dataset that you will be working on is called ReCoNLL 2003, which is a corrected version of the CoNLL 2003 dataset: https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "\n",
    "[Train data](https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing)\n",
    "\n",
    "[Dev data](https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing)\n",
    "\n",
    "[Test data](https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing)\n",
    "\n",
    "As you can see, the annotated texts are labeled according to the IOB annotation scheme, for 3 entity types: Person, Organization, Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a624fe-b56e-4235-8781-569459751093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "from random import sample\n",
    "\n",
    "# External library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Additional imports\n",
    "from itertools import zip_longest\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef23b03-fb0c-4bd6-bfd5-27d5f2889735",
   "metadata": {},
   "source": [
    "`read_data` is a function for reading the data from a single file (of the ones that are provided above). The function receives a file path and then it encodes every sentence individually using a pair of lists, one list contains the words and one list contains the tags. Each list pair will be added to a general list (data), which will be returned from the function.\n",
    "\n",
    "This function reads the files from a remote drive file. If you want to read them locally, adjust the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bba0c47-86a6-4733-939f-223575fcaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    dataset = []\n",
    "    file_id = re.search('https://drive.google.com/file/d/(.*)/view', filepath).group(1)\n",
    "    download_link = \"https://drive.google.com/uc?export=download&id=\" + file_id\n",
    "    temp_path = 'temp.txt'\n",
    "    urllib.request.urlretrieve(download_link, temp_path)\n",
    "    current_sentence = []\n",
    "    with open(temp_path) as file:\n",
    "        for line in file:\n",
    "            if line == \"\\n\":\n",
    "                dataset.append(current_sentence)\n",
    "                current_sentence = []\n",
    "            else:\n",
    "                current_sentence.append(line.split())\n",
    "    return dataset\n",
    "\n",
    "train_data = load_dataset('https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing')\n",
    "dev_data = load_dataset('https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing')\n",
    "test_data = load_dataset('https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3782f4-f6e7-437c-860a-cfd48c545835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rubin', 'B-PER'],\n",
       " [\"'s\", 'O'],\n",
       " ['misfortune', 'O'],\n",
       " ['turned', 'O'],\n",
       " ['into', 'O'],\n",
       " ['a', 'O'],\n",
       " ['very', 'O'],\n",
       " ['lucky', 'O'],\n",
       " ['break', 'O'],\n",
       " ['for', 'O'],\n",
       " ['eighth-seeded', 'O'],\n",
       " ['Olympic', 'O'],\n",
       " ['champion', 'O'],\n",
       " ['Lindsay', 'B-PER'],\n",
       " ['Davenport', 'I-PER'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de303e6e-3cc7-46b6-a9b9-a4c46aa9dfed",
   "metadata": {},
   "source": [
    "Note that each entry in the data is a list of words and their corresponding tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05305e35-1673-4a1d-ba79-aedc6130abe9",
   "metadata": {},
   "source": [
    "The following Vocab class can be served as a dictionary that maps words and tags into Ids. The UNK_TOKEN should be used for words that are not part of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fb5ac3-4c5d-470f-8fc6-ba6175c0d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_TOKEN = 0\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word_to_index = {\"__unk__\": UNKNOWN_TOKEN}\n",
    "        self.index_to_word = {UNKNOWN_TOKEN: \"__unk__\"}\n",
    "        self.word_count = 1\n",
    "\n",
    "        self.tag_to_index = {\"O\":0, \"B-PER\":1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4, \"B-ORG\": 5, \"I-ORG\": 6}\n",
    "        self.index_to_tag = {0:\"O\", 1:\"B-PER\", 2:\"I-PER\", 3:\"B-LOC\", 4:\"I-LOC\", 5:\"B-ORG\", 6:\"I-ORG\"}\n",
    "\n",
    "    def get_word_indices(self, words):\n",
    "        word_indices = [self.get_word_index(w) for w in words]\n",
    "        return word_indices\n",
    "\n",
    "    def get_tag_indices(self, tags):\n",
    "        tag_indices = [self.tag_to_index[t] for t in tags]\n",
    "        return tag_indices\n",
    "\n",
    "    def get_word_index(self, w):\n",
    "        if w not in self.word_to_index:\n",
    "            self.word_to_index[w] = self.word_count\n",
    "            self.index_to_word[self.word_count] = w\n",
    "            self.word_count += 1\n",
    "        return self.word_to_index[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97347aa5-2294-4680-89a4-a4d20a944225",
   "metadata": {},
   "source": [
    "## To do\n",
    "Write a function `prepare_data` that takes a dataset (train, dev, or test) and a Vocab instance as inputs. This function should convert each pair of (words, tags) into a pair of corresponding indexes using the Vocab instance. Each indexed pair should be added to data_sequences, which will be returned by the function.\n",
    "\n",
    "Foer the previous training instance, the answer should look like this:\n",
    "\n",
    "```\n",
    "train_sequences[90] =\n",
    "\n",
    "[(799, 1),\n",
    " (163, 0),\n",
    " (800, 0),\n",
    " (604, 0),\n",
    " (801, 0),\n",
    " (65, 0),\n",
    " (802, 0),\n",
    " (803, 0),\n",
    " (804, 0),\n",
    " (29, 0),\n",
    " (805, 0),\n",
    " (806, 0),\n",
    " (255, 0),\n",
    " (807, 1),\n",
    " (808, 2),\n",
    " (24, 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cdbfd0c-fed5-4b32-aeeb-f57ecbdce875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, vocab):\n",
    "    processed_sequences = []\n",
    "    for sentence in data:\n",
    "        words = []\n",
    "        tags = []\n",
    "        for word in sentence:\n",
    "            vocab.get_word_index(word[0])\n",
    "            words.append(word[0])\n",
    "            tags.append(word[1])\n",
    "            \n",
    "        word_indices = vocab.get_word_indices(words)\n",
    "        tag_indices = vocab.get_tag_indices(tags)\n",
    "        combined_list = list(zip_longest(word_indices, tag_indices, fillvalue=None))\n",
    "        processed_sequences.append(combined_list)\n",
    "    \n",
    "    return processed_sequences, vocab\n",
    "\n",
    "vocab = Vocabulary()\n",
    "\n",
    "train_sequences, vocab = preprocess_data(train_data, vocab)\n",
    "dev_sequences, vocab = preprocess_data(dev_data, vocab)\n",
    "test_sequences, vocab = preprocess_data(test_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d680845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(799, 1),\n",
       " (163, 0),\n",
       " (800, 0),\n",
       " (604, 0),\n",
       " (801, 0),\n",
       " (65, 0),\n",
       " (802, 0),\n",
       " (803, 0),\n",
       " (804, 0),\n",
       " (29, 0),\n",
       " (805, 0),\n",
       " (806, 0),\n",
       " (255, 0),\n",
       " (807, 1),\n",
       " (808, 2),\n",
       " (24, 0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0c4fb",
   "metadata": {},
   "source": [
    "Let's Gooooo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b24ba5-ff1d-433b-8fbf-b1ccd660f8ad",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Write NERNet, a PyTorch Module for labeling words with NER tags.\n",
    "\n",
    "*input_size:* the size of the vocabulary\n",
    "\n",
    "*embedding_size:* the size of the embeddings\n",
    "\n",
    "*hidden_size:* the hidden size\n",
    "\n",
    "*output_size:* the number tags we are predicting for\n",
    "\n",
    "*n_layers:* the number of layers we want to use\n",
    "\n",
    "The input for your forward function should be a single sentence tensor.\n",
    "\n",
    "You are free to experiment with additional architectures such as LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df188ae-a7cd-42b0-aeb5-f8236406409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMNERModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, tagset_size, num_layers):\n",
    "        super(BiLSTMNERModel, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embed_size)\n",
    "        self.bilstm_layer = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear_layer = nn.Linear(hidden_size * 2, tagset_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded_seq = self.embedding_layer(input_seq)  #(batch_size, seq_length, embed_size)\n",
    "        lstm_output, _ = self.bilstm_layer(embedded_seq)  #(batch_size, seq_length, hidden_size * 2)\n",
    "        output = self.linear_layer(lstm_output)  #(batch_size, seq_length, tagset_size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8bb029-24d1-4451-a1ae-7561682fde99",
   "metadata": {},
   "source": [
    "## To do\n",
    "write a training loop, which takes a model (instance of NERNet) and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e54562f4-70ce-417d-8169-c5933044310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, epochs):\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_history = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for sentence in train_sequences:\n",
    "            inputs = torch.tensor([word[0] for word in sentence])\n",
    "            targets = torch.tensor([tag[1] for tag in sentence])\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_function(predictions, targets)\n",
    "\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b8b67-b524-4ad1-959d-931d3b2d5cf8",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "write an evaluation loop on a trained model, using the dev and test datasets. This function prints the precision, recall, f1, and support, of each label separately (7 labels in total), and for all the 6 labels (except O) together. The caption argument for the function should be served for printing so that when you print include it as a prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94023255-a9f0-4f3b-a0bc-ab71cc8326c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop(model, caption):\n",
    "    datasets = ['dev', 'test']\n",
    "    for i, data in enumerate([dev_sequences, test_sequences]):\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        for sentence in data:\n",
    "            inputs = torch.tensor([word[0] for word in sentence])\n",
    "            targets = torch.tensor([tag[1] for tag in sentence])\n",
    "            predictions = model(inputs)\n",
    "            predicted_tags = torch.argmax(predictions, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predicted_tags.detach().numpy())\n",
    "            all_targets.extend(targets.detach().numpy())\n",
    "            \n",
    "\n",
    "        print(f\"{caption} - {datasets[i]} Data:\")  \n",
    "        print(\"Detailed Metrics by Label:\")\n",
    "        print(classification_report(all_targets, all_predictions, labels=[0, 1, 2, 3, 4, 5, 6], target_names=['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']))\n",
    "            \n",
    "        report = classification_report(all_targets, all_predictions, labels=[0, 1, 2, 3, 4, 5, 6], target_names=['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG'], output_dict=True)            \n",
    "\n",
    "        \n",
    "        # Calculate weighted average for precision, recall, and F1-score excluding 'O'\n",
    "        labels_to_consider = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
    "        \n",
    "        precision_sum = 0\n",
    "        recall_sum = 0\n",
    "        f1_sum = 0\n",
    "        total_support = 0\n",
    "\n",
    "        \n",
    "        for label in labels_to_consider:\n",
    "            precision_sum += report[label]['precision'] * report[label]['support']\n",
    "            recall_sum += report[label]['recall'] * report[label]['support']\n",
    "            f1_sum += report[label]['f1-score'] * report[label]['support']\n",
    "            total_support += report[label]['support']\n",
    "        \n",
    "        avg_precision = precision_sum / total_support\n",
    "        avg_recall = recall_sum / total_support\n",
    "        avg_f1 = f1_sum / total_support\n",
    "\n",
    "        print(\"Aggregate Metrics (excluding 'O'):\")\n",
    "        print(f\"Precision: {avg_precision:.2f}\")\n",
    "        print(f\"Recall: {avg_recall:.2f}\")\n",
    "        print(f\"F1-Score: {avg_f1:.2f}\")\n",
    "        print(f\"Support: {total_support}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ac427-8446-4d3c-b244-5bd0349de130",
   "metadata": {},
   "source": [
    "## To do:\n",
    "Train and evaluate at least 5 models.\n",
    "\n",
    "The hyperparameters you can choose are the embedding size, the hidden size and the number of layers in the network.\n",
    "\n",
    "After training, we will use pre-trained GloVe embeddings and see if it affects the performance. Make sure one of the models has an embedding size of 50 so you would be able to load the pre-trained embeddings (if you want, you can go up to 300 dimensions for the pre-trained embeddings).\n",
    "\n",
    "If you are using a CPU, you should keep the embedding size, the hidden size and the number of layers small (50,<100,1-2).\n",
    "\n",
    "If you have a GPU or are using colab, you can easily train larger networks (300, >500, increasing the number of layers won't be as effective so you can still stay at 1-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9a0557",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 with hyperparameters: {'embed_size': 50, 'hidden_size': 64, 'num_layers': 1}\n",
      "Evaluating model 1 on Dev set\n",
      "Model 1 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.88      0.98      0.92      3096\n",
      "       B-PER       0.65      0.46      0.54       200\n",
      "       I-PER       0.72      0.48      0.58       157\n",
      "       B-LOC       0.74      0.49      0.59       183\n",
      "       I-LOC       1.00      0.04      0.08        23\n",
      "       B-ORG       0.53      0.39      0.45       168\n",
      "       I-ORG       0.38      0.04      0.08       116\n",
      "\n",
      "    accuracy                           0.85      3943\n",
      "   macro avg       0.70      0.41      0.46      3943\n",
      "weighted avg       0.83      0.85      0.83      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.63\n",
      "Recall: 0.39\n",
      "F1-Score: 0.46\n",
      "Support: 847\n",
      "\n",
      "Model 1 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.89      0.97      0.93      6567\n",
      "       B-PER       0.71      0.48      0.57       434\n",
      "       I-PER       0.73      0.57      0.64       296\n",
      "       B-LOC       0.66      0.52      0.58       343\n",
      "       I-LOC       1.00      0.13      0.23        53\n",
      "       B-ORG       0.60      0.41      0.49       350\n",
      "       I-ORG       0.35      0.06      0.10       200\n",
      "\n",
      "    accuracy                           0.86      8243\n",
      "   macro avg       0.71      0.45      0.51      8243\n",
      "weighted avg       0.84      0.86      0.84      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.43\n",
      "F1-Score: 0.50\n",
      "Support: 1676\n",
      "\n",
      "Evaluating model 1 on Test set\n",
      "Model 1 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.88      0.98      0.92      3096\n",
      "       B-PER       0.65      0.46      0.54       200\n",
      "       I-PER       0.72      0.48      0.58       157\n",
      "       B-LOC       0.74      0.49      0.59       183\n",
      "       I-LOC       1.00      0.04      0.08        23\n",
      "       B-ORG       0.53      0.39      0.45       168\n",
      "       I-ORG       0.38      0.04      0.08       116\n",
      "\n",
      "    accuracy                           0.85      3943\n",
      "   macro avg       0.70      0.41      0.46      3943\n",
      "weighted avg       0.83      0.85      0.83      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.63\n",
      "Recall: 0.39\n",
      "F1-Score: 0.46\n",
      "Support: 847\n",
      "\n",
      "Model 1 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.89      0.97      0.93      6567\n",
      "       B-PER       0.71      0.48      0.57       434\n",
      "       I-PER       0.73      0.57      0.64       296\n",
      "       B-LOC       0.66      0.52      0.58       343\n",
      "       I-LOC       1.00      0.13      0.23        53\n",
      "       B-ORG       0.60      0.41      0.49       350\n",
      "       I-ORG       0.35      0.06      0.10       200\n",
      "\n",
      "    accuracy                           0.86      8243\n",
      "   macro avg       0.71      0.45      0.51      8243\n",
      "weighted avg       0.84      0.86      0.84      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.43\n",
      "F1-Score: 0.50\n",
      "Support: 1676\n",
      "\n",
      "Training model 2 with hyperparameters: {'embed_size': 100, 'hidden_size': 64, 'num_layers': 1}\n",
      "Evaluating model 2 on Dev set\n",
      "Model 2 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.93      3096\n",
      "       B-PER       0.71      0.54      0.61       200\n",
      "       I-PER       0.71      0.57      0.64       157\n",
      "       B-LOC       0.66      0.55      0.60       183\n",
      "       I-LOC       1.00      0.09      0.16        23\n",
      "       B-ORG       0.59      0.43      0.50       168\n",
      "       I-ORG       0.65      0.15      0.24       116\n",
      "\n",
      "    accuracy                           0.86      3943\n",
      "   macro avg       0.75      0.47      0.53      3943\n",
      "weighted avg       0.85      0.86      0.85      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.68\n",
      "Recall: 0.46\n",
      "F1-Score: 0.53\n",
      "Support: 847\n",
      "\n",
      "Model 2 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.91      0.97      0.94      6567\n",
      "       B-PER       0.75      0.57      0.65       434\n",
      "       I-PER       0.75      0.58      0.66       296\n",
      "       B-LOC       0.74      0.64      0.68       343\n",
      "       I-LOC       1.00      0.28      0.44        53\n",
      "       B-ORG       0.61      0.45      0.52       350\n",
      "       I-ORG       0.48      0.14      0.22       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.75      0.52      0.59      8243\n",
      "weighted avg       0.86      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.50\n",
      "F1-Score: 0.57\n",
      "Support: 1676\n",
      "\n",
      "Evaluating model 2 on Test set\n",
      "Model 2 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.93      3096\n",
      "       B-PER       0.71      0.54      0.61       200\n",
      "       I-PER       0.71      0.57      0.64       157\n",
      "       B-LOC       0.66      0.55      0.60       183\n",
      "       I-LOC       1.00      0.09      0.16        23\n",
      "       B-ORG       0.59      0.43      0.50       168\n",
      "       I-ORG       0.65      0.15      0.24       116\n",
      "\n",
      "    accuracy                           0.86      3943\n",
      "   macro avg       0.75      0.47      0.53      3943\n",
      "weighted avg       0.85      0.86      0.85      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.68\n",
      "Recall: 0.46\n",
      "F1-Score: 0.53\n",
      "Support: 847\n",
      "\n",
      "Model 2 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.91      0.97      0.94      6567\n",
      "       B-PER       0.75      0.57      0.65       434\n",
      "       I-PER       0.75      0.58      0.66       296\n",
      "       B-LOC       0.74      0.64      0.68       343\n",
      "       I-LOC       1.00      0.28      0.44        53\n",
      "       B-ORG       0.61      0.45      0.52       350\n",
      "       I-ORG       0.48      0.14      0.22       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.75      0.52      0.59      8243\n",
      "weighted avg       0.86      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.50\n",
      "F1-Score: 0.57\n",
      "Support: 1676\n",
      "\n",
      "Training model 3 with hyperparameters: {'embed_size': 50, 'hidden_size': 32, 'num_layers': 2}\n",
      "Evaluating model 3 on Dev set\n",
      "Model 3 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.89      0.97      0.93      3096\n",
      "       B-PER       0.60      0.49      0.54       200\n",
      "       I-PER       0.67      0.61      0.64       157\n",
      "       B-LOC       0.69      0.52      0.59       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.64      0.39      0.48       168\n",
      "       I-ORG       0.52      0.09      0.16       116\n",
      "\n",
      "    accuracy                           0.86      3943\n",
      "   macro avg       0.57      0.44      0.48      3943\n",
      "weighted avg       0.83      0.86      0.84      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.61\n",
      "Recall: 0.43\n",
      "F1-Score: 0.49\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.93      6567\n",
      "       B-PER       0.69      0.54      0.61       434\n",
      "       I-PER       0.68      0.60      0.64       296\n",
      "       B-LOC       0.64      0.53      0.58       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.67      0.39      0.49       350\n",
      "       I-ORG       0.59      0.13      0.21       200\n",
      "\n",
      "    accuracy                           0.87      8243\n",
      "   macro avg       0.59      0.45      0.49      8243\n",
      "weighted avg       0.84      0.87      0.85      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.64\n",
      "Recall: 0.45\n",
      "F1-Score: 0.52\n",
      "Support: 1676\n",
      "\n",
      "Evaluating model 3 on Test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.89      0.97      0.93      3096\n",
      "       B-PER       0.60      0.49      0.54       200\n",
      "       I-PER       0.67      0.61      0.64       157\n",
      "       B-LOC       0.69      0.52      0.59       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.64      0.39      0.48       168\n",
      "       I-ORG       0.52      0.09      0.16       116\n",
      "\n",
      "    accuracy                           0.86      3943\n",
      "   macro avg       0.57      0.44      0.48      3943\n",
      "weighted avg       0.83      0.86      0.84      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.61\n",
      "Recall: 0.43\n",
      "F1-Score: 0.49\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.93      6567\n",
      "       B-PER       0.69      0.54      0.61       434\n",
      "       I-PER       0.68      0.60      0.64       296\n",
      "       B-LOC       0.64      0.53      0.58       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.67      0.39      0.49       350\n",
      "       I-ORG       0.59      0.13      0.21       200\n",
      "\n",
      "    accuracy                           0.87      8243\n",
      "   macro avg       0.59      0.45      0.49      8243\n",
      "weighted avg       0.84      0.87      0.85      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.64\n",
      "Recall: 0.45\n",
      "F1-Score: 0.52\n",
      "Support: 1676\n",
      "\n",
      "Training model 4 with hyperparameters: {'embed_size': 100, 'hidden_size': 32, 'num_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 4 on Dev set\n",
      "Model 4 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.91      0.96      0.94      3096\n",
      "       B-PER       0.66      0.56      0.61       200\n",
      "       I-PER       0.71      0.62      0.66       157\n",
      "       B-LOC       0.72      0.63      0.67       183\n",
      "       I-LOC       1.00      0.04      0.08        23\n",
      "       B-ORG       0.59      0.49      0.53       168\n",
      "       I-ORG       0.48      0.28      0.36       116\n",
      "\n",
      "    accuracy                           0.87      3943\n",
      "   macro avg       0.72      0.51      0.55      3943\n",
      "weighted avg       0.86      0.87      0.86      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.52\n",
      "F1-Score: 0.57\n",
      "Support: 847\n",
      "\n",
      "Model 4 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.92      0.97      0.94      6567\n",
      "       B-PER       0.74      0.59      0.66       434\n",
      "       I-PER       0.70      0.69      0.69       296\n",
      "       B-LOC       0.69      0.65      0.67       343\n",
      "       I-LOC       1.00      0.02      0.04        53\n",
      "       B-ORG       0.58      0.45      0.50       350\n",
      "       I-ORG       0.47      0.27      0.34       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.73      0.52      0.55      8243\n",
      "weighted avg       0.87      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.66\n",
      "Recall: 0.53\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n",
      "Evaluating model 4 on Test set\n",
      "Model 4 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.91      0.96      0.94      3096\n",
      "       B-PER       0.66      0.56      0.61       200\n",
      "       I-PER       0.71      0.62      0.66       157\n",
      "       B-LOC       0.72      0.63      0.67       183\n",
      "       I-LOC       1.00      0.04      0.08        23\n",
      "       B-ORG       0.59      0.49      0.53       168\n",
      "       I-ORG       0.48      0.28      0.36       116\n",
      "\n",
      "    accuracy                           0.87      3943\n",
      "   macro avg       0.72      0.51      0.55      3943\n",
      "weighted avg       0.86      0.87      0.86      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.52\n",
      "F1-Score: 0.57\n",
      "Support: 847\n",
      "\n",
      "Model 4 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.92      0.97      0.94      6567\n",
      "       B-PER       0.74      0.59      0.66       434\n",
      "       I-PER       0.70      0.69      0.69       296\n",
      "       B-LOC       0.69      0.65      0.67       343\n",
      "       I-LOC       1.00      0.02      0.04        53\n",
      "       B-ORG       0.58      0.45      0.50       350\n",
      "       I-ORG       0.47      0.27      0.34       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.73      0.52      0.55      8243\n",
      "weighted avg       0.87      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.66\n",
      "Recall: 0.53\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n",
      "Training model 5 with hyperparameters: {'embed_size': 50, 'hidden_size': 64, 'num_layers': 2}\n",
      "Evaluating model 5 on Dev set\n",
      "Model 5 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.98      0.94      3096\n",
      "       B-PER       0.73      0.57      0.64       200\n",
      "       I-PER       0.85      0.64      0.73       157\n",
      "       B-LOC       0.79      0.55      0.65       183\n",
      "       I-LOC       1.00      0.13      0.23        23\n",
      "       B-ORG       0.65      0.46      0.54       168\n",
      "       I-ORG       0.51      0.26      0.34       116\n",
      "\n",
      "    accuracy                           0.87      3943\n",
      "   macro avg       0.77      0.51      0.58      3943\n",
      "weighted avg       0.86      0.87      0.86      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.72\n",
      "Recall: 0.50\n",
      "F1-Score: 0.59\n",
      "Support: 847\n",
      "\n",
      "Model 5 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.94      6567\n",
      "       B-PER       0.76      0.55      0.64       434\n",
      "       I-PER       0.77      0.63      0.69       296\n",
      "       B-LOC       0.73      0.56      0.63       343\n",
      "       I-LOC       1.00      0.25      0.39        53\n",
      "       B-ORG       0.69      0.43      0.53       350\n",
      "       I-ORG       0.43      0.24      0.31       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.75      0.52      0.59      8243\n",
      "weighted avg       0.86      0.88      0.86      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.71\n",
      "Recall: 0.50\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n",
      "Evaluating model 5 on Test set\n",
      "Model 5 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.98      0.94      3096\n",
      "       B-PER       0.73      0.57      0.64       200\n",
      "       I-PER       0.85      0.64      0.73       157\n",
      "       B-LOC       0.79      0.55      0.65       183\n",
      "       I-LOC       1.00      0.13      0.23        23\n",
      "       B-ORG       0.65      0.46      0.54       168\n",
      "       I-ORG       0.51      0.26      0.34       116\n",
      "\n",
      "    accuracy                           0.87      3943\n",
      "   macro avg       0.77      0.51      0.58      3943\n",
      "weighted avg       0.86      0.87      0.86      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.72\n",
      "Recall: 0.50\n",
      "F1-Score: 0.59\n",
      "Support: 847\n",
      "\n",
      "Model 5 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.90      0.97      0.94      6567\n",
      "       B-PER       0.76      0.55      0.64       434\n",
      "       I-PER       0.77      0.63      0.69       296\n",
      "       B-LOC       0.73      0.56      0.63       343\n",
      "       I-LOC       1.00      0.25      0.39        53\n",
      "       B-ORG       0.69      0.43      0.53       350\n",
      "       I-ORG       0.43      0.24      0.31       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.75      0.52      0.59      8243\n",
      "weighted avg       0.86      0.88      0.86      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.71\n",
      "Recall: 0.50\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjusted hyperparameters for CPU\n",
    "cpu_hyperparameters = [\n",
    "    {'embed_size': 50, 'hidden_size': 64, 'num_layers': 1},\n",
    "    {'embed_size': 100, 'hidden_size': 64, 'num_layers': 1},\n",
    "    {'embed_size': 50, 'hidden_size': 32, 'num_layers': 2},\n",
    "    {'embed_size': 100, 'hidden_size': 32, 'num_layers': 2},\n",
    "    {'embed_size': 50, 'hidden_size': 64, 'num_layers': 2}\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "for idx, params in enumerate(cpu_hyperparameters):\n",
    "    vocab_size = vocab.word_count  # Size of the vocabulary\n",
    "    embed_size = params['embed_size']  # Size of the word embeddings\n",
    "    hidden_size = params['hidden_size']  # Size of the hidden state in the RNN\n",
    "    tagset_size = 7  # Number of NER tags\n",
    "    num_layers = params['num_layers']  # Number of layers in the RNN\n",
    "    epochs = 10  # Number of epochs to train for\n",
    "\n",
    "    model = BiLSTMNERModel(vocab_size, embed_size, hidden_size, tagset_size, num_layers).to(device)\n",
    "    print(f\"Training model {idx+1} with hyperparameters: {params}\")\n",
    "    training_loop(model, epochs)\n",
    "    \n",
    "    # Evaluate on Dev set\n",
    "    print(f\"Evaluating model {idx+1} on Dev set\")\n",
    "    evaluation_loop(model, f\"Model {idx+1} - Dev\")\n",
    "    \n",
    "    # Evaluate on Test set\n",
    "    print(f\"Evaluating model {idx+1} on Test set\")\n",
    "    evaluation_loop(model, f\"Model {idx+1} - Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1512d8",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "### Hyperparameters\n",
    "- Bidirectional LSTM\n",
    "- Embedding Size: 50\n",
    "- Hidden Size: 64\n",
    "- Number of Layers: 2\n",
    "\n",
    "### Evaluation Metrics on Dev Set\n",
    "\n",
    "#### Metrics for Each Label Separately\n",
    "| Label  | Precision | Recall | F1-Score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| O      | 0.90      | 0.97   | 0.94     | 3096    |\n",
    "| B-PER  | 0.73      | 0.57   | 0.64     | 200     |\n",
    "| I-PER  | 0.85      | 0.64   | 0.73     | 157     |\n",
    "| B-LOC  | 0.79      | 0.55   | 0.65     | 183     |\n",
    "| I-LOC  | 1.00      | 0.13   | 0.23     | 23      |\n",
    "| B-ORG  | 0.65      | 0.46   | 0.54     | 168     |\n",
    "| I-ORG  | 0.51      | 0.26   | 0.34     | 116     |\n",
    "\n",
    "#### Overall Metrics\n",
    "- **Accuracy**: 0.87 (3943 samples)\n",
    "- **Macro Average**:\n",
    "  - Precision: 0.77\n",
    "  - Recall: 0.51\n",
    "  - F1-Score: 0.58\n",
    "- **Weighted Average**:\n",
    "  - Precision: 0.86\n",
    "  - Recall: 0.87\n",
    "  - F1-Score: 0.86\n",
    "- **Metrics combined (excluding 'O')**:\n",
    "  - Precision: 0.72\n",
    "  - Recall: 0.50\n",
    "  - F1-Score: 0.59\n",
    "  - Support: 847\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation Metrics on Test Set\n",
    "\n",
    "#### Metrics for Each Label Separately\n",
    "| Label  | Precision | Recall | F1-Score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| O      | 0.90      | 0.97   | 0.94     | 6567    |\n",
    "| B-PER  | 0.76      | 0.55   | 0.64     | 434     |\n",
    "| I-PER  | 0.77      | 0.63   | 0.69     | 296     |\n",
    "| B-LOC  | 0.73      | 0.56   | 0.63     | 343     |\n",
    "| I-LOC  | 1.00      | 0.25   | 0.39     | 53      |\n",
    "| B-ORG  | 0.69      | 0.43   | 0.53     | 350     |\n",
    "| I-ORG  | 0.43      | 0.24   | 0.31     | 200     |\n",
    "\n",
    "#### Overall Metrics\n",
    "- **Accuracy**: 0.88 (8243 samples)\n",
    "- **Macro Average**:\n",
    "  - Precision: 0.75\n",
    "  - Recall: 0.52\n",
    "  - F1-Score: 0.59\n",
    "- **Weighted Average**:\n",
    "  - Precision: 0.86\n",
    "  - Recall: 0.88\n",
    "  - F1-Score: 0.86\n",
    "- **Metrics combined (excluding 'O')**:\n",
    "  - Precision: 0.71\n",
    "  - Recall: 0.50\n",
    "  - F1-Score: 0.58\n",
    "  - Support: 1676"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b72fac-3782-4fa6-836d-0603a85f24fa",
   "metadata": {},
   "source": [
    "## To do\n",
    "Download the GloVe embeddings from https://nlp.stanford.edu/projects/glove/ (use the 50-dim vectors from glove.6B.zip for shorter training, 300-dim for maximum performance). Then initialize the nn.Embedding module in your NERNet with these embeddings, so that you can start your training with pre-trained vectors. Repeat the previous part with the same hyperparameters and print the results for each model.\n",
    "\n",
    "Note: make sure that vectors are aligned with the IDs in your Vocab, in other words, make sure that for example the word with ID 0 is the first vector in the GloVe matrix of vectors that you initialize nn.Embedding with. For a discussion on how to do that, check this link:\n",
    "https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03c1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            coefs = np.asarray(parts[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "    return embeddings\n",
    "\n",
    "# Load the 50-dim and 100-dim embeddings\n",
    "glove_50d = fetch_glove_embeddings('glove.6B/glove.6B.50d.txt')\n",
    "glove_100d = fetch_glove_embeddings('glove.6B/glove.6B.100d.txt')\n",
    "\n",
    "def construct_embedding_matrix(glove_embeds, vocab, embed_dim):\n",
    "    matrix = np.zeros((vocab.word_count, embed_dim))\n",
    "    for word, idx in vocab.word_to_index.items():\n",
    "        vector = glove_embeds.get(word)\n",
    "        if vector is not None:\n",
    "            matrix[idx] = vector\n",
    "        else:\n",
    "            # Initialize with random embedding if word is not in GloVe\n",
    "            matrix[idx] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
    "    return matrix\n",
    "\n",
    "embedding_matrix_100d = construct_embedding_matrix(glove_100d, vocab, 100)\n",
    "embedding_matrix_50d = construct_embedding_matrix(glove_50d, vocab, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144ce49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMNERPreTrained(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, tagset_size, num_layers, embedding_matrix):\n",
    "        super(BiLSTMNERPreTrained, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.bilstm_layer = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional=True)\n",
    "        self.linear_layer = nn.Linear(hidden_size * 2, tagset_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded_seq = self.embedding_layer(input_seq)\n",
    "        lstm_output, _ = self.bilstm_layer(embedded_seq)\n",
    "        output = self.linear_layer(lstm_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42edc4d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pre-trained model 1 with hyperparameters: {'embed_size': 50, 'hidden_size': 64, 'num_layers': 1}\n",
      "Evaluating pre-trained model 1 on Dev set\n",
      "Model 1 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.92      0.98      0.95      3096\n",
      "       B-PER       0.76      0.63      0.69       200\n",
      "       I-PER       0.77      0.71      0.74       157\n",
      "       B-LOC       0.70      0.52      0.60       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.56      0.48      0.52       168\n",
      "       I-ORG       0.45      0.22      0.29       116\n",
      "\n",
      "    accuracy                           0.88      3943\n",
      "   macro avg       0.59      0.50      0.54      3943\n",
      "weighted avg       0.86      0.88      0.87      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.52\n",
      "F1-Score: 0.57\n",
      "Support: 847\n",
      "\n",
      "Model 1 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.97      0.95      6567\n",
      "       B-PER       0.75      0.59      0.66       434\n",
      "       I-PER       0.74      0.71      0.72       296\n",
      "       B-LOC       0.67      0.58      0.62       343\n",
      "       I-LOC       1.00      0.06      0.11        53\n",
      "       B-ORG       0.57      0.52      0.54       350\n",
      "       I-ORG       0.41      0.27      0.32       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.72      0.53      0.56      8243\n",
      "weighted avg       0.87      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.66\n",
      "Recall: 0.54\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n",
      "Evaluating pre-trained model 1 on Test set\n",
      "Model 1 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.92      0.98      0.95      3096\n",
      "       B-PER       0.76      0.63      0.69       200\n",
      "       I-PER       0.77      0.71      0.74       157\n",
      "       B-LOC       0.70      0.52      0.60       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.56      0.48      0.52       168\n",
      "       I-ORG       0.45      0.22      0.29       116\n",
      "\n",
      "    accuracy                           0.88      3943\n",
      "   macro avg       0.59      0.50      0.54      3943\n",
      "weighted avg       0.86      0.88      0.87      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.52\n",
      "F1-Score: 0.57\n",
      "Support: 847\n",
      "\n",
      "Model 1 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.97      0.95      6567\n",
      "       B-PER       0.75      0.59      0.66       434\n",
      "       I-PER       0.74      0.71      0.72       296\n",
      "       B-LOC       0.67      0.58      0.62       343\n",
      "       I-LOC       1.00      0.06      0.11        53\n",
      "       B-ORG       0.57      0.52      0.54       350\n",
      "       I-ORG       0.41      0.27      0.32       200\n",
      "\n",
      "    accuracy                           0.88      8243\n",
      "   macro avg       0.72      0.53      0.56      8243\n",
      "weighted avg       0.87      0.88      0.87      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.66\n",
      "Recall: 0.54\n",
      "F1-Score: 0.58\n",
      "Support: 1676\n",
      "\n",
      "Training pre-trained model 2 with hyperparameters: {'embed_size': 100, 'hidden_size': 64, 'num_layers': 1}\n",
      "Evaluating pre-trained model 2 on Dev set\n",
      "Model 2 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.98      0.96      3096\n",
      "       B-PER       0.75      0.68      0.71       200\n",
      "       I-PER       0.78      0.73      0.75       157\n",
      "       B-LOC       0.74      0.66      0.70       183\n",
      "       I-LOC       1.00      0.13      0.23        23\n",
      "       B-ORG       0.62      0.48      0.54       168\n",
      "       I-ORG       0.51      0.32      0.39       116\n",
      "\n",
      "    accuracy                           0.89      3943\n",
      "   macro avg       0.76      0.57      0.61      3943\n",
      "weighted avg       0.88      0.89      0.88      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.58\n",
      "F1-Score: 0.62\n",
      "Support: 847\n",
      "\n",
      "Model 2 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      6567\n",
      "       B-PER       0.82      0.63      0.71       434\n",
      "       I-PER       0.81      0.76      0.78       296\n",
      "       B-LOC       0.66      0.65      0.65       343\n",
      "       I-LOC       0.83      0.19      0.31        53\n",
      "       B-ORG       0.60      0.57      0.58       350\n",
      "       I-ORG       0.47      0.35      0.40       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.73      0.59      0.63      8243\n",
      "weighted avg       0.89      0.90      0.89      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.59\n",
      "F1-Score: 0.64\n",
      "Support: 1676\n",
      "\n",
      "Evaluating pre-trained model 2 on Test set\n",
      "Model 2 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.98      0.96      3096\n",
      "       B-PER       0.75      0.68      0.71       200\n",
      "       I-PER       0.78      0.73      0.75       157\n",
      "       B-LOC       0.74      0.66      0.70       183\n",
      "       I-LOC       1.00      0.13      0.23        23\n",
      "       B-ORG       0.62      0.48      0.54       168\n",
      "       I-ORG       0.51      0.32      0.39       116\n",
      "\n",
      "    accuracy                           0.89      3943\n",
      "   macro avg       0.76      0.57      0.61      3943\n",
      "weighted avg       0.88      0.89      0.88      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.58\n",
      "F1-Score: 0.62\n",
      "Support: 847\n",
      "\n",
      "Model 2 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      6567\n",
      "       B-PER       0.82      0.63      0.71       434\n",
      "       I-PER       0.81      0.76      0.78       296\n",
      "       B-LOC       0.66      0.65      0.65       343\n",
      "       I-LOC       0.83      0.19      0.31        53\n",
      "       B-ORG       0.60      0.57      0.58       350\n",
      "       I-ORG       0.47      0.35      0.40       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.73      0.59      0.63      8243\n",
      "weighted avg       0.89      0.90      0.89      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.59\n",
      "F1-Score: 0.64\n",
      "Support: 1676\n",
      "\n",
      "Training pre-trained model 3 with hyperparameters: {'embed_size': 50, 'hidden_size': 32, 'num_layers': 2}\n",
      "Evaluating pre-trained model 3 on Dev set\n",
      "Model 3 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.98      0.96      3096\n",
      "       B-PER       0.75      0.71      0.73       200\n",
      "       I-PER       0.75      0.87      0.80       157\n",
      "       B-LOC       0.71      0.56      0.63       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.65      0.45      0.53       168\n",
      "       I-ORG       0.54      0.22      0.31       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.62      0.54      0.57      3943\n",
      "weighted avg       0.88      0.90      0.88      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.67\n",
      "Recall: 0.57\n",
      "F1-Score: 0.60\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.97      0.96      6567\n",
      "       B-PER       0.71      0.65      0.68       434\n",
      "       I-PER       0.75      0.81      0.78       296\n",
      "       B-LOC       0.66      0.58      0.62       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.64      0.46      0.54       350\n",
      "       I-ORG       0.53      0.37      0.44       200\n",
      "\n",
      "    accuracy                           0.89      8243\n",
      "   macro avg       0.60      0.55      0.57      8243\n",
      "weighted avg       0.88      0.89      0.88      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.57\n",
      "F1-Score: 0.60\n",
      "Support: 1676\n",
      "\n",
      "Evaluating pre-trained model 3 on Test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.98      0.96      3096\n",
      "       B-PER       0.75      0.71      0.73       200\n",
      "       I-PER       0.75      0.87      0.80       157\n",
      "       B-LOC       0.71      0.56      0.63       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.65      0.45      0.53       168\n",
      "       I-ORG       0.54      0.22      0.31       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.62      0.54      0.57      3943\n",
      "weighted avg       0.88      0.90      0.88      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.67\n",
      "Recall: 0.57\n",
      "F1-Score: 0.60\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.97      0.96      6567\n",
      "       B-PER       0.71      0.65      0.68       434\n",
      "       I-PER       0.75      0.81      0.78       296\n",
      "       B-LOC       0.66      0.58      0.62       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.64      0.46      0.54       350\n",
      "       I-ORG       0.53      0.37      0.44       200\n",
      "\n",
      "    accuracy                           0.89      8243\n",
      "   macro avg       0.60      0.55      0.57      8243\n",
      "weighted avg       0.88      0.89      0.88      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.65\n",
      "Recall: 0.57\n",
      "F1-Score: 0.60\n",
      "Support: 1676\n",
      "\n",
      "Training pre-trained model 4 with hyperparameters: {'embed_size': 100, 'hidden_size': 32, 'num_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating pre-trained model 4 on Dev set\n",
      "Model 4 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      3096\n",
      "       B-PER       0.75      0.70      0.73       200\n",
      "       I-PER       0.80      0.85      0.82       157\n",
      "       B-LOC       0.72      0.65      0.68       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.66      0.48      0.56       168\n",
      "       I-ORG       0.59      0.36      0.45       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.64      0.58      0.60      3943\n",
      "weighted avg       0.89      0.90      0.90      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.61\n",
      "F1-Score: 0.64\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      6567\n",
      "       B-PER       0.79      0.66      0.72       434\n",
      "       I-PER       0.78      0.79      0.78       296\n",
      "       B-LOC       0.66      0.66      0.66       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.71      0.51      0.59       350\n",
      "       I-ORG       0.52      0.42      0.47       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.63      0.57      0.60      8243\n",
      "weighted avg       0.89      0.90      0.90      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.60\n",
      "F1-Score: 0.64\n",
      "Support: 1676\n",
      "\n",
      "Evaluating pre-trained model 4 on Test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      3096\n",
      "       B-PER       0.75      0.70      0.73       200\n",
      "       I-PER       0.80      0.85      0.82       157\n",
      "       B-LOC       0.72      0.65      0.68       183\n",
      "       I-LOC       0.00      0.00      0.00        23\n",
      "       B-ORG       0.66      0.48      0.56       168\n",
      "       I-ORG       0.59      0.36      0.45       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.64      0.58      0.60      3943\n",
      "weighted avg       0.89      0.90      0.90      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.61\n",
      "F1-Score: 0.64\n",
      "Support: 847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      6567\n",
      "       B-PER       0.79      0.66      0.72       434\n",
      "       I-PER       0.78      0.79      0.78       296\n",
      "       B-LOC       0.66      0.66      0.66       343\n",
      "       I-LOC       0.00      0.00      0.00        53\n",
      "       B-ORG       0.71      0.51      0.59       350\n",
      "       I-ORG       0.52      0.42      0.47       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.63      0.57      0.60      8243\n",
      "weighted avg       0.89      0.90      0.90      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.69\n",
      "Recall: 0.60\n",
      "F1-Score: 0.64\n",
      "Support: 1676\n",
      "\n",
      "Training pre-trained model 5 with hyperparameters: {'embed_size': 50, 'hidden_size': 64, 'num_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\royef\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating pre-trained model 5 on Dev set\n",
      "Model 5 - Dev - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      3096\n",
      "       B-PER       0.74      0.74      0.74       200\n",
      "       I-PER       0.80      0.85      0.82       157\n",
      "       B-LOC       0.73      0.62      0.67       183\n",
      "       I-LOC       0.57      0.17      0.27        23\n",
      "       B-ORG       0.70      0.54      0.61       168\n",
      "       I-ORG       0.62      0.40      0.48       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.73      0.61      0.65      3943\n",
      "weighted avg       0.90      0.90      0.90      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.72\n",
      "Recall: 0.63\n",
      "F1-Score: 0.67\n",
      "Support: 847\n",
      "\n",
      "Model 5 - Dev - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96      6567\n",
      "       B-PER       0.74      0.69      0.71       434\n",
      "       I-PER       0.76      0.80      0.78       296\n",
      "       B-LOC       0.67      0.65      0.66       343\n",
      "       I-LOC       0.69      0.21      0.32        53\n",
      "       B-ORG       0.69      0.52      0.59       350\n",
      "       I-ORG       0.58      0.49      0.53       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.72      0.62      0.65      8243\n",
      "weighted avg       0.90      0.90      0.90      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.63\n",
      "F1-Score: 0.65\n",
      "Support: 1676\n",
      "\n",
      "Evaluating pre-trained model 5 on Test set\n",
      "Model 5 - Test - dev Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96      3096\n",
      "       B-PER       0.74      0.74      0.74       200\n",
      "       I-PER       0.80      0.85      0.82       157\n",
      "       B-LOC       0.73      0.62      0.67       183\n",
      "       I-LOC       0.57      0.17      0.27        23\n",
      "       B-ORG       0.70      0.54      0.61       168\n",
      "       I-ORG       0.62      0.40      0.48       116\n",
      "\n",
      "    accuracy                           0.90      3943\n",
      "   macro avg       0.73      0.61      0.65      3943\n",
      "weighted avg       0.90      0.90      0.90      3943\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.72\n",
      "Recall: 0.63\n",
      "F1-Score: 0.67\n",
      "Support: 847\n",
      "\n",
      "Model 5 - Test - test Data:\n",
      "Detailed Metrics by Label:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96      6567\n",
      "       B-PER       0.74      0.69      0.71       434\n",
      "       I-PER       0.76      0.80      0.78       296\n",
      "       B-LOC       0.67      0.65      0.66       343\n",
      "       I-LOC       0.69      0.21      0.32        53\n",
      "       B-ORG       0.69      0.52      0.59       350\n",
      "       I-ORG       0.58      0.49      0.53       200\n",
      "\n",
      "    accuracy                           0.90      8243\n",
      "   macro avg       0.72      0.62      0.65      8243\n",
      "weighted avg       0.90      0.90      0.90      8243\n",
      "\n",
      "Aggregate Metrics (excluding 'O'):\n",
      "Precision: 0.70\n",
      "Recall: 0.63\n",
      "F1-Score: 0.65\n",
      "Support: 1676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models with pre-trained GloVe embeddings\n",
    "for idx, params in enumerate(cpu_hyperparameters):\n",
    "    vocab_size = vocab.word_count  # Size of the vocabulary\n",
    "    embed_size = params['embed_size']  # Size of the word embeddings\n",
    "    hidden_size = params['hidden_size']  # Size of the hidden state in the RNN\n",
    "    tagset_size = 7  # Number of NER tags\n",
    "    num_layers = params['num_layers']  # Number of layers in the RNN\n",
    "    epochs = 10  # Number of epochs to train for\n",
    "\n",
    "    if embed_size == 50:\n",
    "        embedding_matrix = embedding_matrix_50d\n",
    "    else:\n",
    "        embedding_matrix = embedding_matrix_100d\n",
    "\n",
    "    model = BiLSTMNERPreTrained(vocab_size, embed_size, hidden_size, tagset_size, num_layers, embedding_matrix).to(device)\n",
    "    print(f\"Training pre-trained model {idx+1} with hyperparameters: {params}\")\n",
    "    training_loop(model, epochs)\n",
    "    \n",
    "    # Evaluate on Dev set\n",
    "    print(f\"Evaluating pre-trained model {idx+1} on Dev set\")\n",
    "    evaluation_loop(model, f\"Model {idx+1} - Dev\")\n",
    "    \n",
    "    # Evaluate on Test set\n",
    "    print(f\"Evaluating pre-trained model {idx+1} on Test set\")\n",
    "    evaluation_loop(model, f\"Model {idx+1} - Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24080a12",
   "metadata": {},
   "source": [
    "## Best Pre-Trained Model\n",
    "\n",
    "### Hyperparameters\n",
    "- Bidirectional LSTM\n",
    "- Embedding Size: 50\n",
    "- Hidden Size: 64\n",
    "- Number of Layers: 2\n",
    "\n",
    "### Evaluation Metrics on Dev Set\n",
    "\n",
    "#### Metrics for Each Label Separately\n",
    "| Label  | Precision | Recall | F1-Score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| O      | 0.94      | 0.98   | 0.96     | 3096    |\n",
    "| B-PER  | 0.74      | 0.74   | 0.74     | 200     |\n",
    "| I-PER  | 0.80      | 0.85   | 0.82     | 157     |\n",
    "| B-LOC  | 0.73      | 0.62   | 0.67     | 183     |\n",
    "| I-LOC  | 0.57      | 0.17   | 0.27     | 23      |\n",
    "| B-ORG  | 0.70      | 0.54   | 0.61     | 168     |\n",
    "| I-ORG  | 0.62      | 0.40   | 0.48     | 116     |\n",
    "\n",
    "#### Overall Metrics\n",
    "- **Accuracy**: 0.90 (3943 samples)\n",
    "- **Macro Average**:\n",
    "  - Precision: 0.73\n",
    "  - Recall: 0.61\n",
    "  - F1-Score: 0.65\n",
    "- **Weighted Average**:\n",
    "  - Precision: 0.90\n",
    "  - Recall: 0.90\n",
    "  - F1-Score: 0.90\n",
    "- **Metrics combined (excluding 'O')**:\n",
    "  - Precision: 0.72\n",
    "  - Recall: 0.63\n",
    "  - F1-Score: 0.67\n",
    "  - Support: 847\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation Metrics on Test Set\n",
    "\n",
    "#### Metrics for Each Label Separately\n",
    "| Label  | Precision | Recall | F1-Score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| O      | 0.95      | 0.97   | 0.96     | 6567    |\n",
    "| B-PER  | 0.74      | 0.69   | 0.71     | 434     |\n",
    "| I-PER  | 0.76      | 0.80   | 0.78     | 296     |\n",
    "| B-LOC  | 0.67      | 0.65   | 0.66     | 343     |\n",
    "| I-LOC  | 0.69      | 0.21   | 0.32     | 53      |\n",
    "| B-ORG  | 0.69      | 0.52   | 0.59     | 350     |\n",
    "| I-ORG  | 0.58      | 0.49   | 0.53     | 200     |\n",
    "\n",
    "#### Overall Metrics\n",
    "- **Accuracy**: 0.90 (8243 samples)\n",
    "- **Macro Average**:\n",
    "  - Precision: 0.72\n",
    "  - Recall: 0.62\n",
    "  - F1-Score: 0.65\n",
    "- **Weighted Average**:\n",
    "  - Precision: 0.90\n",
    "  - Recall: 0.90\n",
    "  - F1-Score: 0.90\n",
    "- **Metrics combined (excluding 'O')**:\n",
    "  - Precision: 0.70\n",
    "  - Recall: 0.63\n",
    "  - F1-Score: 0.65\n",
    "  - Support: 1676\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2de89",
   "metadata": {},
   "source": [
    "We can see that there is an improvment from the network i created and the pre trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
